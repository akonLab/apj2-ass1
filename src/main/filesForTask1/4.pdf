56 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
2019 26th international conference on high performance computing, data, and analytics workshop (hipcw) 
visually introducing freshmen to low-level 
java  
abstractions for creating, synchronizing and 
coordinating threads  
prasun dewan  
department of computer science  
university of north carolina  
chapel hill, usa dewan@cs.unc.edu  
    
  
abstract— we have developed and experimented with an 
approach to teach low-level java concurrency abstractions in our 
first required course for cs majors, which assumes knowledge of 
procedural programming. the driving problems are visualized 
simulations of multiple physical objects in motion that may (a) be 
confined to a shared space and (b) coordinate with each other. such 
simulations do not require any domain-specific knowledge such as 
sorting and image processing for driving problems and exercises, 
and their implementation demonstrates the benefits of object-
based programming. they allow focus on both the performance 
and programmability benefits of concurrency, provide analogies 
for an abstraction-independent explanation of concurrency 
concepts, and can be used to incrementally motivate all low-level 
concurrency abstractions and visualize the effect of using and not 
using these abstractions. layered simulation-based worked 
examples illustrating the abstractions were presented and easily 
understood in multiple offerings of a course that implemented this 
approach. students implemented non-trivial assignments based on 
these abstractions, even when they were optional, did not face 
major obstacles because of visual error feedback, and were excited 
by concurrency as they felt it empowered them to implement 
arbitrary applications early.   
keywords—education, simulations, animations, object-oriented 
programming, thread creation, synchronized methods, wait, notify, 
autonomous threads, java, interleaving, concurrency  
i. introduction   
the motivation for teaching concurrency is relatively 
straightforward. it is replete with concepts that are difficult to 
self-learn and are the foundation for a variety of fields such as 
high-performance computing, real-time systems, operating 
systems, programming languages, distributed and cloud 
computing, and software engineering. recent advances in 
computer hardware have increased the range of systems that 
make practical use of concurrency, and thus, increased its 
importance.  
this increase has spurred interest in pedagogical methods for 
teaching concurrency and the coupled concept of distributed 
computing, together often referred to as pdc (parallel and 
distributed computing). the national science foundation has 
started a center to encourage such methods [1], which, in turn, 
has produced a book on this topic [2].   
  
arguably, the research resulting from these efforts has only 
scratched the surface in the field of concurrency education. 
teaching of sequential programming is still an active research 
area, even though such programming has been extensively 
taught ever since computing was invented. on the other hand, 
concurrency has been taught mainly in niche, typically 
nonrequired and/or graduate courses, such as operating systems 
and real-time systems. many recent efforts have suggested 
adding concurrency earlier to courses that have traditionally 
addressed only sequential programming. as there are many 
ways to couple concurrency concepts with a course on 
sequential computing, the design space of concurrency 
education is larger than that of sequential-programming. yet 
another argument for more work in this area is provided by 
ghafoor et al [3], who estimate that less than 10% of the 
universities and community colleges that offer cs/ce degrees 
cover concurrency at the undergraduate level.  
our university traditionally covered concurrency only in one 
undergraduate course – the operating system course – which is 
not required and is typically taken by juniors and seniors. this 
paper describes the author’s effort to introduce concurrency in 
the first required course for cs majors, referred to as our target 
course. it assumes knowledge of procedural programming.   
in this paper, we focus on the contribution this effort makes 
to the field of concurrency education. the novelty of a 
pedagogical method can manifest itself in both the set of 
requirements it attempts to meet and the approach used to meet 
these requirements. in other words, the method can be 
distinguished by both what it is trying to cover and how it is 
meeting its goal. we address both aspects below.  
we first develop a requirement space for describing a range 
of practical requirements existing pdc pedagogical methods 
 
this work was funded in part by nsf award oac-1924059.  
978-1-7281-4894-6/19/$31.00 ©2019 ieee 
doi 10.1109/hipcw.2019.00022 
57 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
have been developed to meet. we then identify a new point in 
this space that, to the best of our knowledge, no published paper 
in this area has met. the remainder of the paper presents a key 
idea in our work to meet our goal –using simulations of multiple 
physical objects as driving problems in worked examples and 
student exercises.  
ii. requirement  space and goal   
concurrency can be introduced in a special course on this 
concept [4] or added to one  [5-8]  or more [9, 10] courses 
addressing different topics/domains in computer science.   
the evolutionary approach has been taken in many efforts, 
and they can be distinguished by the topic of the course to which 
concurrency is added. some introduce concurrency in the very 
first course on programming [5, 8]. others have assumed prior 
experience with programming and have targeted cs2 [7, 8] or 
upper-level courses [11, 12]. typically, cs2 is a data structure 
course, in which many have introduced concurrency[7, 8].  
 table i.   domain vs. concurrency orientation  
orientation    
concurrency oriented  [4]  
domain-oriented  [5-10](this paper)  
 table ii.   domains/topics  embellished with concurrency  
domain    
intro. programming  [5, 13]  
data structures  [7, 8]  
object-based programming  (this paper)  
upper-level courses  [11, 12]  
a course on parallelism must not only introduce the notion 
of concurrency but also abstractions for implementing it. some 
concurrency courses cover high-level/declarative abstractions 
such as message-passing [5] and fork-join and reduce [6, 8]; 
while some address low-level/procedural ones such as explicit 
thread-creation [7, 13]. the low-level abstractions offer more 
flexibility but require more code to program.  
 table iii.   range of concurrency abstractions  
abstraction-level    
low- 
level/procedural  
threads, synchronization [7, 13] and 
this paper; runnable interface,  
coordination (this paper)  
high- 
level/declarative  
[5-8]  
a related issue is the programming language in which these 
abstractions are supported. these languages have included a 
visual programming language called scratch [5], c [4, 8],  
python [5, 6],  and java [7, 13].  
 table iv.   languages used for programming concurrency  
language kind    
visual  scratch[5]  
procedural  c[4, 8]  
object-based  python[5, 6]; java [7, 13], this 
paper  
there are two complementary reasons for making a program 
concurrent. the first is to make an algorithm faster but not easier 
to program by executing parallelized tasks concurrently. the 
second is to make an algorithm easier to program but not faster. 
in this approach, the automatic context-switching offered by 
concurrency abstractions relieves the programmer from 
implementing it.  
most of the surveyed work has focused on performance, 
discussing parallelization of a variety of tasks such as scanning 
[6], sorting [6, 7], monte carlo pi estimation [4], image 
processing [3, 4]  and printing [5], that can execute faster when 
multiple cores/processors are available. arguably, this 
parallelization makes programming of these tasks more difficult 
as it requires the additional steps of thread creation and 
typically, synchronization and coordination.  
a striking example of the dual approach is using parallel 
communicating threads to make it easier to program a person 
moving with a ball [5] – the person and ball can be made 
separate threads that communicate with each other. as these 
threads are closely coupled and represent one autonomous 
activity, parallelization would reduce performance because of 
the overhead of thread creation and message passing.   
other examples have taken a hybrid approach by targeting 
multiple autonomous activities such as the conway game of 
life [4, 14], and the froggertm, tetris and centipede games, 
multiple independent atm withdrawals [4, 13], and a single 
server connected to multiple clients [15]. parallelization both 
saves programmers from implementing context-switching of 
such activities and increases performance when multiple cores 
are available.  
 table v.   concurrenct diriving problems  
metric  driving problems  
performance  scanning [6]; sorting [6, 7]; monte 
carlo pi estimation [4]; image 
processing [3, 4]; conway game of 
life [4, 14]; froggertm, tetris and 
centipede games [13],  objects in  
motion (this paper)  
programmability  single ball-mover animation [5];  
conway game of life [4, 14];  atm 
withdrawals [4, 13],  
froggertm, tetris and centipede  
games [13],  objects in motion  (this 
paper)  
our target course assumes knowledge of the basic 
procedural programming concepts of primitive types, arrays, 
loops and procedures, and is taken by many freshmen. it does 
not cover data structures, and goes beyond the basic concepts by 
teaching object-based programming in java [16]. we designed 
58 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
the concurrency addition to meet the following unique set of 
requirements:   
1. integration with object-based programming - the topic of 
the target course.   
2. coverage of all concurrency concepts provided by the java 
language - thread creation by implementing a runnable 
interface or extending a thread class, synchronized 
methods, wait, notify, notifyall - but not the higher-level 
java library constructs such as fork-join and thread pools.   
3. focus on both performance and programmability benefits 
of concurrency.  
to the best of our knowledge, no other published method on 
early concurrency meets requirements 1 and 2. table iii shows 
that coordination (notify and notifyall) is not addressed by 
surveyed methods covering low-level concurrency abstractions. 
table iv shows that none of these methods has considered 
adding concurrency to a course that focuses on object-based 
programming and assumes knowledge of procedural 
programming. in other words, we know of no other effort that 
has experimented with teaching all java language abstractions 
in a course on object-oriented programming that focuses on both 
programmability and performance benefits. we describe below 
how we have met this unaddressed set of requirements.   
 iii.  autonomous  interacting objects in motion  
ideally, a course introducing concurrency must have the 
following four components.  
1. an abstraction-independent explanation of the concepts of 
interleaved and concurrent execution of multiple activities 
within a process, and synchronization and coordination of 
them.  
2. layered explanations of the behavior of a set of thread 
abstractions to support such activities.  
3. layered worked-examples that illustrate these abstractions 
by showing (a) how they can be programmed to implement 
realistic driving problems, and (b) the (programmability, 
performance and correctness) consequences of using and 
not using the abstractions for the problem.  
4. layered student exercises to use these abstractions.  
courses on operating system take the further step of also 
explaining the implementation of concurrency abstractions. the 
challenge in early introduction of concurrency is to include these 
four components without addressing the implementation of 
thread abstractions. our key idea to meet this challenge was 
using as driving problems visual simulations of autonomous 
interacting objects in motion. this idea has been implicitly used 
in the design of several assignments (table v). here we 
explicitly articulate and motivate it as a foundation for 
concurrency analogies, driving problems, and exercises.   
a. rationale  
there are many reasons for choosing such objects in a course 
introducing both object-based programming and concurrency.   
real-life analogies: these objects occur in real life; thus, 
they can be used for analogies to provide an 
abstractionindependent explanation of concurrency.   
prerequisite free: their parallel computer simulations can 
be motivated without requiring knowledge of other 
computerscience concepts such as image processing.   
demonstrate benefits of object-based programming: 
simulations of physical phenomenon are particularly suited for 
object-based programming (the first object-based language, 
simula-67, was targeted at simulations), the subject of our target 
course.  
programmability and performance: these objects represent 
multiple autonomous activities; thus, their parallelization offers 
both programmability and performance benefits.   
synchronization illustration: by confining them to a shared 
space, synchronization constructs – in our course, java 
synchronized methods - can be motivated and explained.   
coordination illustration: by choosing cooperating objects, 
coordination constructs – in our course, java wait, notify and 
notifyall - can be motivated and explained.   
concurrency visualization: the effect of using concurrency, 
synchronization and coordination mechanisms correctly can be 
visualized.  
layered, incremental introduction: it is possible to create 
related driving problems and exercises that require concurrency 
but not synchronization or coordination, and those that require 
synchronization but not coordination, allowing these three 
concepts to be introduced and implemented incrementally.   
b. analogies  
analogies involving physical objects in motion allowed us 
to meet the goal of providing an abstraction-independent 
explanation of concurrency. two hands juggling three balls 
(figure 1(a)) corresponded to two processors executing three 
threads. preventing collision among three balls in a shared space 
(figure 1(a)), two cars in the same lane (figure 1(b), vehicles at 
an intersection (figure 1(c)), and two cooperative runners 
exchanging batons (figure 1(f)) corresponded to safe access to 
shared data by concurrent synchronized threads. runners 
(figure 1(e)) and vehicles (figure 1(b)) allocated to different 
lanes corresponded to safe access to different data structures by 
unsynchronized threads. baton exchange between two 
cooperating relay runners (figure 1(f)) corresponded to thread 
coordination to achieve some joint task.  
  
                          (a)                               (b)  
            
(c)                                  (d)  
          
59 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
   
     (e)                                           (f)  
fig. 1. analogies involving objects in motion  
c. prerequisites and layering of worked examples  
all of our worked examples involve the animation of a space 
shuttle from the origin of a cartesian plane to a destination 
coordinate. (the icon for the shuttle remains horizontal through 
its flight.) this animation is implemented by an animator object 
that provides an animatefromorigin method, which takes as 
arguments a shuttle object and its destination. the method 
moves the shuttle first in the y direction and then in the x 
direction by calling the animateyfromorigin and 
animatexfromorigin methods, respectively. in some 
coordinated examples, the animators make use of two different 
objects, called “clearance managers”, responsible for notifying 
waiting animators. multiple implementations of the animator 
and clearance managers are used in the examples, which are 
related by inheritance. also, the user-interface in the worked 
examples was implemented using the model-view-controller 
design pattern [16, 17]. thread implementation through 
subclassing of the thread class and implementation of  the 
runnable interface was covered. therefore, the examples and 
underlying concepts were introduced after interfaces, 
inheritance and mvc are taught. with a different, less modular, 
coding style, they could be taught after interface or inheritance.  
d. sequential vs concurrent execution  
to illustrate the difference between sequential and 
concurrent method execution, we created a sequential and 
concurrent worked example. in the sequential example, a single 
thread executes animatefromorigin sequentially in two 
instances of ashuttleanimator to move two different shuttles. 
in the concurrent case, two different threads execute the method 
in two different animator instances controlling separate shuttles.  
figures 2 (a, b) and 3 (a, b) shows the difference in the 
behavior of the two programs. in the sequential case, the x 
coordinate of the left shuttle changes, while the right shuttle 
remains stationary, as we transition from snapshot (a) to (b). in 
the concurrent/interleaved case, the y coordinates of both 
shuttles change in snapshots (a) and (b), giving an appearance 
of concurrent movement.  
the console traces in figure 2(c) and figure 3(c) show the 
difference in algorithms in the two cases. in the sequential case, 
a single animator object (ashuttleanimator@1901648626) 
executes the y and x loops in the main thread created 
automatically by java. in the concurrent case, the main thread 
uses the java thread object to create and start two threads, 
[shuttle animation 1,5,main] and  [shuttle animation 
2,5,main], respectively, which use two different animator 
objects, to execute the animatefromorigin method. as a result, 
the traces produced by the two executions are interleaved. 
figure 3(c) also shows the asynchronous code execution 
possible with thread creation – the parent thread terminates with 
a message before the children it created finish execution.   
e. synchronized vs unsynchronized concurrency  
to illustrate the need for thread synchronization, we create 
two instances of ashuttleanimator that control a single shuttle, 
taking it along the paths (y11, y12, …) and (y21, y22, …), 
respectively. we fork from the main thread two threads that 
concurrently execute the animatefromorigin method in the two 
animators.   
  
  
a) shuttle1 at position x11, shuttle2 stationary  
  
b) shuttle1 at position x12, shuttle2 stationary  
thread[main,5,main] started animating in y direction 
in:ashuttleanimator@1901648626  
thread[main,5,main] finished animating in y direction 
in:ashuttleanimator@1901648626  
thread[main,5,main] started animating in x direction 
in:ashuttleanimator@1901648626  
thread[main,5,main] finished animating in x direction 
in:ashuttleanimator@1901648626  
thread[main,5,main] started animating in y direction 
in:ashuttleanimator@2144912729  
thread[main,5,main] finished animating in y direction 
in:ashuttleanimator@2144912729  
thread[main,5,main] started animating in x direction 
in:ashuttleanimator@2144912729  
thread[main,5,main] finished animating in x direction 
in:ashuttleanimator@2144912729  
main terminates  
     c) single main thread, single animator, two controller shuttles  
fig. 2. independent serial shuttle animators  
  
a) shuttle1 at position y11, shuttle2 at position y21  
  
b) shuttle1 at position y12,  shuttle2 at position y21  
thread:thread[main,5,main] has started thread[shuttle animation 
1,5,main]  
thread:thread[main,5,main] has started thread[shuttle animation  
2,5,main]  
main terminates  
thread[shuttle animation 2,5,main] started animating in y direction 
in:ashuttleanimator@673226183  
thread[shuttle animation 1,5,main] started animating in y  
direction in:ashuttleanimator@2114748546  
thread[shuttle animation 2,5,main] finished animating in y  
direction in:ashuttleanimator@673226183  
thread[shuttle animation 2,5,main] started animating in x direction 
in:ashuttleanimator@673226183  
thread[shuttle animation 1,5,main] finished animating in y  
direction in:ashuttleanimator@2114748546  
thread[shuttle animation 1,5,main] started animating in x direction 
in:ashuttleanimator@2114748546  
            
60 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
thread[shuttle animation 1,5,main] finished animating in x  
direction in:ashuttleanimator@2114748546  
    (c) two animators, two created interleaved threads  
fig. 3. independent concurrent shuttle animators  
figure 4(a..d) shows that when the method is not 
synchronized, the shuttle oscillates between the trajectories 
computed by the animators taking y coordinates (y11, y21, y12, 
y22, ,…). figure 5(a..d) shows that when the method is 
synchronized, the shuttle first follows the trajectory computed 
by the first animator, taking y positions (y11, y12 …), and then 
the trajectory computed by the second animator, taking y 
positions (y21, y22 , …).  figure 4(e) and 5(e) trace the fact that 
in both cases the same algorithm executes, involving two 
animators and threads. the difference is interleaving of y 
movements in the unsynchronized case – the second shuttle 
starts movement in the y direction before the first one finishes 
movement in that direction.  
f. internal vs external coordination  
thread coordination involves concurrent activities that are 
related to each other and together accomplish some larger goal. 
as mentioned earlier, in our analogies of figure 1, they 
correspond to runners racing competitively or cooperatively in 
a race (figure 1(e, f)).   
the activities of a set of related threads may be coordinated 
internally by each of the threads or be controlled externally by a 
single thread. in our analogies, internal control corresponds to 
two cooperating runners ensuring they coordinate their baton 
exchange themselves, while external control corresponds to a set 
of runners waiting for a whistle from a referee to start the race. 
in our shuttle example, this corresponds to a set of shuttles going 
on a joint mission. in the external case, their flights are 
controlled by methods of an external air traffic controller object 
being executed by a separate thread, or internally by the methods 
of their animators executed by different threads. in both cases, 
the animator methods perform blocking wait operations. in the 
internal case, they also execute notify or notifyall, while in the 
external case, a thread manipulating the external controller 
(which itself does not wait) executes the unblocking operations  
g. external coordination   
to support external coordination, we built a special 
visualized class called aclearancemanager, whose wait method 
can be called in a synchronized method to block a thread. an 
instance of this class displays the queue of threads that are 
waiting to be notified. the class also provides a proceed button 
to interactively execute its notify method in a synchronized 
method called proceed. we also implemented a special case of 
this class, abroadcastingclearancemanager, which provides an 
additional proceed all button to call notifyall in a synchronized 
method called proceedall to unblock all waiting threads.  
figure 6 shows the use of a global aclearancemanager. two 
separate shuttles are controlled by two different animators, 
which, this time, are instances of  
ashuttleanimatorwatitingforclearance. they are like the ones 
we saw earlier, except that they execute the wait method in the 
aclearancemanager at the start of their animatefromorigin 
method. figure 6(a) shows them in the displayed queue. figure 
6(b) shows the effect of interactively pressing the proceed 
button. the first animator is removed from the queue and starts 
moving its shuttle. figure 6(c) shows that clicking the proceed 
button again dequeues the second thread, which now starts 
animating the second shuttle.  
figure 6(c) shows the behavior of the wait calls executed by 
the animatefromorigin method of the new animator. the 
execution by the first (second) thread is blocked until the first 
(second) execution of the notify call in the clearance manager 
by the awt (user-interface) thread.  
  
  (a) at pos y11             (b) at pos y21          (c) at pos y12          (d) at pos y21   
thread:thread[main,5,main] has started thread[shuttle animation  
1,5,main]  
thread[shuttle animation 1,5,main] started animating in y  
direction in:ashuttleanimator@1817260044  
thread:thread[main,5,main] has started thread[shuttle animation  
2,5,main]  
thread[shuttle animation 2,5,main] started animating in y direction 
in:ashuttleanimator@1817260044  
thread[shuttle animation 1,5,main] finished animating in y direction 
in:ashuttleanimator@1817260044  
thread[shuttle animation 1,5,main] started animating in x  
direction in:ashuttleanimator@1817260044  
thread[shuttle animation 2,5,main] finished animating in y  
direction in:ashuttleanimator@1817260044  
thread[shuttle animation 2,5,main] started animating in x  
direction in:ashuttleanimator@1817260044  
thread[shuttle animation 1,5,main] finished animating in x  
direction in:ashuttleanimator@1817260044  
              (e) two threads, no synchronization  
fig. 4. single shuttle controlled by two unsynchronized animators  
   
(a)at pos y11             (b) at pos y12          (c) at pos y21          (d) at pos y22   
thread:thread[main,5,main] has started thread[shuttle animation  
1,5,main]  
thread[shuttle animation 1,5,main] started animating in y  
direction in:asynchronizedshuttleanimator@1890996505  
thread:thread[main,5,main] has started thread[shuttle animation  
2,5,main]  
thread[shuttle animation 1,5,main] finished animating in y  
direction in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 1,5,main] started animating in x  
direction in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 1,5,main] finished animating in x direction 
in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 2,5,main] started animating in y  
direction in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 2,5,main] finished animating in y  
direction in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 2,5,main] started animating in x  
direction in:asynchronizedshuttleanimator@1890996505  
thread[shuttle animation 2,5,main] finished animating in x direction 
in:asynchronizedshuttleanimator@1890996505  
                e) two threads, with synchronization  
fig. 5. single shuttle controlled by two synchronized animators  
to illustrate notiifyall, we created animators whose 
animatefromorigin method performs a wait on 
abroacastingclearancemanager. as before, the method 
executions by the two threads block. figure 7(b) shows that 
when the proceed all button is pressed, both threads are 
unblocked. figure 7 (c) shows that the button press results in 
61 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
abroacastingclearancemanager calling notifyall in the awt 
thread, which causes all waiting threads to unblock from their 
wait calls.  
  
(a) both threads waiting in queue  
 
(b) first thread dequeued by notify, starting first animation  
  
(c) second thread dequeued by notify, starting second animation  
thread[animation thread 0,6,main] before wait  
thread[animation thread 1,6,main] before wait  
thread[awt-eventqueue-0,6,main] after notify  
thread[animation thread 0,6,main] after wait  
thread[animation  thread  0,6,main]  started  animating  in  y  direction  
in:ashuttleanimatorwatitingforclearance@1783146483  
thread[awt-eventqueue-0,6,main] after notify  
thread[animation thread 1,6,main]:after wait  
thread[animation  thread  1,6,main]  started  animating  in 
 y  direction in:ashuttleanimatorwatitingforclearance@62182667  
…  
d) traces of notify and wait calls  
fig. 6. externally coordinated  launch of a single shuttle at a time   
  
(a) both threads waiting in queue  
  
(b) both threads dequeued by notifyall, starting both animations  
  
thread[awt-eventqueue-0,6,main]: after notifyall  
thread[animation thread 0,6,main]: after wait  
thread[animation thread 1,6,main]: after wait  
(c) notifyall unblocks all waits  
fig. 7. externally coordinated  launch of multiple shuttles at a time   
h. internal coordination   
as mentioned earlier, the coordination in figures 6 and 7 
corresponds to flight takeoffs being controlled by an external 
agent such as an air traffic controller. once in air, shuttles should 
be responsible for coordinating their trajectories. to simulate 
such internal coordination, we implemented the alock class, 
which has a boolean variable. it offers a lock operation that 
waits if the boolean is true and unlock operation that invokes 
notify and sets the boolean to false. we created a new kind of 
animator, acontrolledshuttleanimator. before (after) calling 
animateyfromorigin, the method calls the lock (unlock) 
operation on a lock. we created three instances of this class that 
use the same lock, and three threads to execute their 
animatefromorigin method on three different shuttles. figure 
8(a..d) shows the coordination among the three animators.   
  
(a) three shuttles ready to launch  
  
(b) first animator gets lock for y axis and launches first shuttle  
  
(c) second animator gets released lock and launches second shuttle  
  
(d) third animator gets released lock and launches third shuttle  
thread[animation thread 0,6,main] waiting for 
lock:lectures.animation.threads.wait_notify.lock.alock@5145d7f0 
thread[animation thread 0,6,main] got  
lock:lectures.animation.threads.wait_notify.lock.alock@5145d7f0  
thread[animation thread 0,6,main] started animating in y  
direction in:acontrolledshuttleanimator@1248334686 thread[animation 
thread 1,6,main] waiting for 
lock:lectures.animation.threads.wait_notify.lock.alock@5145d7f0 
thread[animation thread 2,6,main] waiting for 
lock:lectures.animation.threads.wait_notify.lock.alock@5145d7f0  
thread[animation thread 0,6,main] finished animating in y  
direction in:acontrolledshuttleanimator@1248334686  
thread[animation thread 0,6,main] returning from releaselock  
thread[animation thread 0,6,main] started animating in x  
direction in:acontrolledshuttleanimator@1248334686  
…  
(e) three lock operations, each unlock causes the oldest lock to unblock  
fig. 8. internally-coordinated launch of  multiple shuttles   
the animateyfromorigin method of all three animators 
execute the lock operation of the shared instance of alock. the 
first animator gets the lock first, and keeps it until it reaches its 
highest y position (figure 8(b)). at this point, the method 
releases the lock, allowing the second waiting animator to start 
animating in the y direction (figure 8(c)), which releases its 
lock when it reaches its highest position, causing the last 
animator to start moving its shuttle (figure 8(d)). the trace of 
62 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
figure 8(e) shows that each unlock causes the oldest lock 
invocation to unblock.  
i. project and experience  
as mentioned earlier, our target course focuses on 
objectbased programming, whose benefits are manifested in 
large evolving programs. therefore, the course requires a set of 
layered assignments that together implement a semester-wide 
project. the nature of the projects we have given is inspired by 
the alice programming environment [18], which allows novice 
programmers to interactively implement and call procedures 
that create and manipulate objects in a predefined 3-d virtual 
environment. in our projects, students do not use a predefined 
alice environment; instead, they implement from scratch an 
alice-inspired project that provides commands to manipulate 
objects in a 2-d virtual environment. the projects have varied. 
for instance, one of the projects has been a halloween 
simulation of “trick or treat” [15]. the most recent project 
simulates the bridge scene in the movie “monty python and the 
holy grail” in which king arthur and his knights attempt to 
cross a bridge after answering questions posed by a guard.   
a virtual environment is particularly well suited for 
concurrency assignments involving objects in motion. we 
illustrate using the bridge scene project. to exercise 
concurrency, students create animators that make avatars of 
arthur, galahad, robin and lancelot move simultaneously. to 
exercise synchronization, they synchronize access by multiple 
threads that manipulate the same knight. to exercise thread 
coordination, taking liberties with the bridge scene, they create 
threads and animators that make the knights clap to a beat set by 
the guard. the concurrency abstractions can be used directly in 
the implemented simulations or indirectly by end-users of the 
simulation who interactively call commands to create and 
coordinate threads.   
figure 9(a..c) shows the end-user entering commands to 
create synchronized clapping. figure 9(a) defines the beat 
procedure to simulate a single beat, which makes the guard tuck 
its arms in, sleep for 500ms, spread its arms out, call proceedall 
in abroadcastingclearancemanager, and then sleep for 200ms. 
figure 9(b) defines the beats procedure to simulate multiple 
beats, which calls beat 5 times. figure 9(c) invokes the beats 
procedure in a separate thread.  
before calling the beat procedure, the user calls an animation 
method for each knight, executed by a separate thread,  that 
moves the knight’s arms in and out in response to notifications 
from the clearance manager. thus, when the beat procedure is 
called, the knights and guard move their arms in unison – when 
the guard moves his arms out (in), so do the knights, as shown 
in figure 9(d) (figure 9(e)).  
the author has taught the concurrency-augmented target 
course once almost every year since fall 2012. concurrency, 
synchronization, and coordination have been parts of the last 
three assignments (a10, a11, a12), respectively, which are also 
responsible for command parsing and interpretation (the bulk of 
the assignments), implementation and use of generic types, 
implementation and use of exception classes, and undo/redo. in 
all of these offerings, a1-a9 were required. in different 
offerings, some or all features of a10-a12 were made extra 
credit based on the quizzes added to the course.   
  
(a) interactive definition of a single beat  
 
(b) interactive definition of a beat sequence  
 
(c) interactive call to execute beat sequence in a thread  
  
(d) coordinated guard and knight arms out  
  
(e) coordinated guard and knight arms in  
fig. 9. knights clapping to a beat set by the guard  
table vi shows two data points. in fall 2012, all three 
assignments were required, and almost all students who 
submitted the last concurrency-unware assignment also 
submitted the concurrency-aware ones. in fall 2018, all three 
were optional. though students had less time and incentive to 
implement the concurrency-aware assignments, almost half of 
them did so. our experience shows that (a) the visual approach 
made it easy for students to understand concurrency and the java 
language abstractions for supporting it, (b) the concurrency 
aspects of the assignments did not create major obstacles in any 
of our offerings, as they were applications of the concurrency 
patterns [8, 19] demonstrated in the worked examples and gave 
visual feedback in case of  errors, and (c)  students felt excited  
by concurrency as they believed its knowledge empowered them 
to implement any application. this excitement is consistent with 
that reported in other work [13].  
63 
authorized licensed use limited to: university of north carolina at chapel hill. downloaded on september 03,2020 at 19:22:14 utc from ieee xplore.  restrictions apply.  
 table vi.   required vs optional  concurrency assignments  
semester  a8  a9  a10  a11  a12  
f2018   61  59  45  33  28  
f2012  73  70  67  67  67  
 iv.  summary and future work  
the contributions of this paper are (a) a five-dimensional 
(tables i to v) space that succinctly compares the goals of 
existing work on concurrency pedagogy, (b) identification of a 
new practical point in this space, (c) motivation of a visual 
approach to support this point, (d) and layered worked examples 
and project-based exercises that implemented this approach in 
multiple offerings of our target course.  
while we have implemented our approach in a singlemodule 
course on java object-based programming, the general idea is 
applicable in a variety of contexts. the presentation of this idea 
in this paper has shown no java code. thus, it can be applied to 
a course taught in other object-based languages by 
implementing the driving problems and clearance managers in 
these languages. it can also  be applied to a course in other 
languages such as c by providing more labor-intensive code for 
creating worked examples and student exercises. it is 
particularly suitable for a multi-module introduction to 
concurrency, wherein our worked examples and assignments 
can be an additional module taught in java or other languages.   
it will be attractive to create such ports as future work, and 
to use our current examples directly in the large number of 
javabased courses offered today that cover the prerequisite for 
our concurrency module – interfaces or inheritance. future work 
can also address how the concurrency concepts and worked 
examples should be learned by students – should they participate 
in live lectures, watch videos, or do hands-on manipulation of 
worked examples [5], or use some mix of these techniques? it 
would also be useful to explore early introduction of starvation 
and deadlock. further work is needed to develop techniques for 
automatic assessment of concurrent programs to both help 
grading of finished exercises and provide guidance while they 
are being developed  
[1] prasad, s.k., a. gupta, a. rosenberg, a. sussman, and c. weems.  
cder center | nsf/ieee-tcpp curriculum initiative,” nsf/ieeetcpp 
curriculum initiative. 2017; available from: 
https://grid.cs.gsu.edu/~tcpp/curriculum/?q=node/21183.  
[2] prasad, s.k., a. gupta, a.l. rosenberg, a. sussman, and c.c. weems, 
topics in parallel and distributed computing: introducing concurrency in 
undergraduate courses. 2015: morgan kaufmann publishers inc. 360.  
[3] ghafoor, s., d.w. brown, and m. rogers. integrating parallel computing 
in introductory programming classes: an experience and lesson 
learned. in proceedings of the euro-edupar 2017 workshop of 23rd 
international european conference on parallel and distributed 
computing. 2017.  
[4] ko, y., b. burgstaller, and b. scholz, parallel from the beginning: the case 
for multicore programming in thecomputer science undergraduate 
curriculum, in proceeding of the 44th acm technical symposium on 
computer science education. 2013, acm: denver, colorado, usa. p. 
415-420.  
[5] bogaerts, s., hands-on parallelism with no prerequisites and little time 
using scratch, in topics in parallel and distributed computing: 
introducing concurrency in undergraduate courses, 1st edition, s. 
prasad, a. gupta, a. rosenberg, a. sussman, and c. weems, editor. 2019, 
morgan kaufmann.  
[6] cormen, t.h., parallel computing in a python-based computer science 
course, in topics in parallel and distributed computing: introducing  
concurrency in undergraduate courses, 1st edition, s. prasad, a. gupta, 
a. rosenberg, a. sussman, and c. weems, editor. 2019, morgan 
kaufmann.  
[7] grossman, d., fork-join parallelism with a data-structures focus, in 
topics in parallel and distributed computing: introducing concurrency in 
undergraduate courses, 1st edition, s. prasad, a. gupta, a. rosenberg, 
a. sussman, and c. weems, editor. 2019, morgan kaufmann.  
[8] adams, j.c., injecting parallel computing into cs2, in proceedings of the 
45th acm technical symposium on computer science education. 2014, 
acm: atlanta, georgia, usa. p. 277-282.  
[9] bunde, d.p., modules for introducing threads, in topics in parallel and 
distributed computing: introducing concurrency in undergraduate 
courses, 1st edition, s. prasad, a. gupta, a. rosenberg, a. sussman, and 
c. weems, editor. 2019, morgan kaufmann.  
[10] burtscher, m., w. peng, a. qasem, h. shi, d. tamir, and h. thiry, a 
module-based approach to adopting the 2013 acm curricular 
recommendations on parallel computing, in proceedings of the 46th 
acm technical symposium on computer science education. 2015, 
acm: kansas city, missouri, usa. p. 36-41.  
[11] geist, r., j.a. levine, and j. westall, a problem-based learning approach 
to gpu computing, in proceedings of the workshop on education for 
high-performance computing. 2015, acm: austin, texas. p. 1-8.  
[12] lupo, c., z.j. wood, and c. victorino, cross teaching parallelism and ray 
tracing: a project-based approach to teaching applied parallel computing, 
in proceedings of the 43rd acm technical symposium on computer 
science education. 2012, acm: raleigh, north carolina, usa. p. 
523528.  
[13] bruce, k.b., a. danyluk, and t. murtagh, introducing concurrency in cs 
1, in proc. acm sigcse'10. 2010, acm.  
[14] eijkhout, v., parallel programming illustrated through conway’s game 
of life, in topics in parallel and distributed computing: introducing  
concurrency in undergraduate courses, 1st edition, s. prasad, a. gupta, 
a. rosenberg, a. sussman, and c. weems, editor. 2019, morgan 
kaufmann.  
[15] dewan, p. the structure of a project-based course on the fundamentals 
of distributed computing. in proc. of eduhipc-18 worksahop in ieee 
hipc. 2018.  
[16] dewan, p. teaching inter-object design patterns to freshmen. in proc. 
sigcse. 2005.  
[17] krasner, g.e. and s.t. pope, a cookbook for using the model-
viewcontroller user interface paradigm in smalltalk-80. journal of 
objectoriented programming, 1988. 1(3): p. 26-49.  
[18] cooper, s., w. dann, and r. pausch, alice: a 3-d tool for introductory 
programming concepts. j. comput. sci. coll., 2000: p. 107-116.  
[19] keutzer, k., b. massingill, t. mattson, and b.s. 2010. a design pattern 
language for engineering (parallel) software: merging the plpp and 
opl projects. in 2010 workshop on parallel programming pattern 
(carefree, az), paraplop’10. 2010.  
